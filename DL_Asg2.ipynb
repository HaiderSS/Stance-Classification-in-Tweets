{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk                            # Cleaning the data\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from keras.preprocessing import sequence,text\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Embedding,LSTM,SpatialDropout1D,Bidirectional\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17994973869249935294\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 8133044015714963998\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4839348633\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 14802762287292926413\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1660 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 15343173787345564870\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('Pickle_files/train_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc =df[df['Target'] == 'Atheism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Target</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>dear lord thank u for all of ur blessings forg...</td>\n",
       "      <td>Atheism</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>blessed are the peacemakers for they shall be ...</td>\n",
       "      <td>Atheism</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>i am not conformed to this world i am transfor...</td>\n",
       "      <td>Atheism</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>salah should be prayed with focus and understa...</td>\n",
       "      <td>Atheism</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>and stay in your houses and do not display you...</td>\n",
       "      <td>Atheism</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>be amazeda real unicorns among us narwhals semst</td>\n",
       "      <td>Atheism</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>thjuly  saw independence from the oppression o...</td>\n",
       "      <td>Atheism</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>thy kingdom come thy will be done on earth as ...</td>\n",
       "      <td>Atheism</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>aamirkhan says in pk tht fasting in the name o...</td>\n",
       "      <td>Atheism</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>atheistq men never commit evil so fully and jo...</td>\n",
       "      <td>Atheism</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>513 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Tweet   Target   Stance\n",
       "100  dear lord thank u for all of ur blessings forg...  Atheism  AGAINST\n",
       "101  blessed are the peacemakers for they shall be ...  Atheism  AGAINST\n",
       "102  i am not conformed to this world i am transfor...  Atheism  AGAINST\n",
       "103  salah should be prayed with focus and understa...  Atheism  AGAINST\n",
       "104  and stay in your houses and do not display you...  Atheism  AGAINST\n",
       "..                                                 ...      ...      ...\n",
       "608   be amazeda real unicorns among us narwhals semst  Atheism  AGAINST\n",
       "609  thjuly  saw independence from the oppression o...  Atheism  AGAINST\n",
       "610  thy kingdom come thy will be done on earth as ...  Atheism  AGAINST\n",
       "611  aamirkhan says in pk tht fasting in the name o...  Atheism  AGAINST\n",
       "612  atheistq men never commit evil so fully and jo...  Atheism  AGAINST\n",
       "\n",
       "[513 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = hc['Tweet']\n",
    "target = hc['Stance']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split( train_X, target , test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max length of the review\n",
    "\n",
    "r_len=[]\n",
    "for text in hc['Tweet']:\n",
    "    word=word_tokenize(text)\n",
    "    l=len(word)\n",
    "    r_len.append(l)\n",
    "    \n",
    "MAX_REVIEW_LEN=np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_features = 2140\n",
    "max_words = 350\n",
    "batch_size = 128\n",
    "epochs = 6\n",
    "num_classes=1\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_val = sequence.pad_sequences(X_val, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(410, 350) (103, 350)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word, *arr):\n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "    \n",
    "def get_embed_mat(EMBEDDING_FILE, max_features,embed_dim):\n",
    "    # word vectors\n",
    "    embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE, encoding='utf8'))\n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "    # embedding matrix\n",
    "    word_index = tokenizer.word_index\n",
    "    num_words = min(max_features, len(word_index) + 1)\n",
    "    all_embs = np.stack(embeddings_index.values()) #for random init\n",
    "    embedding_matrix = np.random.normal(all_embs.mean(), all_embs.std(), \n",
    "                                        (num_words, embed_dim))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    max_features = embedding_matrix.shape[0]\n",
    "    return embedding_matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "(2140, 300)\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_FILE = 'glove.6B/glove.6B.300d.txt'\n",
    "embed_dim = 300 #word vector dim\n",
    "embedding_matrix = get_embed_mat(EMBEDDING_FILE,max_features,embed_dim)\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Y_train)\n",
    "Y_train = le.transform(Y_train)\n",
    "Y_val = le.transform(Y_val)\n",
    "\n",
    "Y_train = to_categorical(Y_train, dtype =\"uint8\") \n",
    "Y_val = to_categorical(Y_val, dtype =\"uint8\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 350, 300)          642000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_5 (Spatial (None, 350, 300)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 128)               186880    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 829,267\n",
      "Trainable params: 829,267\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim, input_length=X_train.shape[1],weights=[embedding_matrix],trainable=True))\n",
    "model.add(SpatialDropout1D(0.25))\n",
    "# model.add(Bidirectional(LSTM(128,return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(64,return_sequences=False)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 1.4836 - val_accuracy: 0.6893\n",
      "Epoch 2/15\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.1841 - val_accuracy: 0.7184\n",
      "Epoch 3/15\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.0137 - accuracy: 0.9927 - val_loss: 1.3643 - val_accuracy: 0.7184\n",
      "Epoch 4/15\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.3433 - val_accuracy: 0.7087\n",
      "Epoch 5/15\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.1810 - val_accuracy: 0.7476\n",
      "Epoch 6/15\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2546 - val_accuracy: 0.6990\n",
      "Epoch 7/15\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.3033 - val_accuracy: 0.6990\n",
      "Epoch 8/15\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2901 - val_accuracy: 0.7087\n",
      "Epoch 9/15\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.2818 - val_accuracy: 0.7184\n",
      "Epoch 10/15\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 0.0104 - accuracy: 0.9976 - val_loss: 1.1888 - val_accuracy: 0.7087\n",
      "Epoch 11/15\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 1.3107 - val_accuracy: 0.6990\n",
      "Epoch 12/15\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.1679 - val_accuracy: 0.6990\n",
      "Epoch 13/15\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.2756 - val_accuracy: 0.7184\n",
      "Epoch 14/15\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2782 - val_accuracy: 0.7282\n",
      "Epoch 15/15\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.0046 - accuracy: 0.9976 - val_loss: 1.2539 - val_accuracy: 0.7379\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val),epochs=15, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9997020e-01, 2.4971110e-05, 4.8812208e-06],\n",
       "       [3.1015006e-01, 3.1093019e-01, 3.7891978e-01],\n",
       "       [1.9416224e-02, 6.9817441e-04, 9.7988564e-01],\n",
       "       [5.6589567e-03, 1.6662093e-01, 8.2772011e-01],\n",
       "       [1.0687821e-03, 4.1838828e-03, 9.9474734e-01],\n",
       "       [9.9989188e-01, 4.5857993e-05, 6.2173924e-05],\n",
       "       [6.7865808e-04, 5.7751691e-04, 9.9874383e-01],\n",
       "       [9.9996054e-01, 3.1193205e-05, 8.1923463e-06],\n",
       "       [3.7846013e-04, 1.3458034e-03, 9.9827576e-01],\n",
       "       [8.2294595e-05, 8.3064544e-05, 9.9983466e-01],\n",
       "       [9.9986970e-01, 1.2079585e-04, 9.5036212e-06],\n",
       "       [9.2109942e-01, 1.4447543e-03, 7.7455811e-02],\n",
       "       [9.9995852e-01, 3.8726346e-05, 2.7573240e-06],\n",
       "       [2.3468649e-01, 2.5335771e-01, 5.1195580e-01],\n",
       "       [9.9949944e-01, 1.8992396e-04, 3.1064541e-04],\n",
       "       [5.3653662e-04, 5.1028505e-02, 9.4843501e-01],\n",
       "       [9.9416310e-01, 2.6036603e-03, 3.2332586e-03],\n",
       "       [9.9996078e-01, 3.6819594e-05, 2.3497048e-06],\n",
       "       [3.6844797e-03, 1.1225493e-03, 9.9519300e-01],\n",
       "       [9.9994838e-01, 3.7244306e-05, 1.4446095e-05],\n",
       "       [2.6137382e-03, 1.1865613e-03, 9.9619967e-01],\n",
       "       [2.1580100e-02, 1.5495460e-01, 8.2346529e-01],\n",
       "       [1.2918063e-01, 8.5600056e-03, 8.6225939e-01],\n",
       "       [9.9973482e-01, 1.1039429e-04, 1.5477624e-04],\n",
       "       [8.2357961e-01, 4.7061004e-02, 1.2935939e-01],\n",
       "       [1.1287484e-03, 2.3688572e-04, 9.9863440e-01],\n",
       "       [2.6297914e-02, 6.9153318e-03, 9.6678680e-01],\n",
       "       [9.9966061e-01, 1.5703816e-04, 1.8226946e-04],\n",
       "       [6.3449545e-05, 7.7164012e-05, 9.9985933e-01],\n",
       "       [2.4774482e-03, 1.2714007e-04, 9.9739540e-01],\n",
       "       [2.2974539e-04, 1.6736226e-03, 9.9809664e-01],\n",
       "       [9.9996614e-01, 2.7985281e-05, 5.8469991e-06],\n",
       "       [9.9962890e-01, 3.1594995e-05, 3.3953504e-04],\n",
       "       [4.4099224e-04, 1.3587630e-03, 9.9820018e-01],\n",
       "       [8.9458430e-01, 1.0253903e-01, 2.8767404e-03],\n",
       "       [1.3068854e-03, 7.3897390e-04, 9.9795413e-01],\n",
       "       [9.9966240e-01, 1.8539259e-04, 1.5212879e-04],\n",
       "       [9.2931676e-01, 7.0388764e-02, 2.9444555e-04],\n",
       "       [9.7647482e-01, 2.2806155e-02, 7.1897771e-04],\n",
       "       [9.9996781e-01, 2.4646353e-05, 7.5189787e-06],\n",
       "       [9.9996364e-01, 3.0943145e-05, 5.3820941e-06],\n",
       "       [7.6099895e-02, 2.2582335e-03, 9.2164183e-01],\n",
       "       [9.9763107e-01, 5.3728773e-04, 1.8315492e-03],\n",
       "       [9.9768686e-01, 5.1328825e-04, 1.7998422e-03],\n",
       "       [7.8485280e-01, 1.1484572e-03, 2.1399875e-01],\n",
       "       [9.9664080e-01, 1.2653199e-03, 2.0939175e-03],\n",
       "       [7.8914836e-03, 9.3205917e-01, 6.0049340e-02],\n",
       "       [2.1375478e-03, 6.4309186e-04, 9.9721932e-01],\n",
       "       [9.9927217e-01, 5.6176441e-04, 1.6602875e-04],\n",
       "       [1.0494352e-03, 4.5656082e-03, 9.9438500e-01],\n",
       "       [3.0058134e-02, 1.4939547e-03, 9.6844792e-01],\n",
       "       [1.9791078e-02, 9.7274131e-01, 7.4675749e-03],\n",
       "       [9.2025286e-01, 7.2218105e-04, 7.9024971e-02],\n",
       "       [9.6209913e-01, 3.9625536e-03, 3.3938289e-02],\n",
       "       [9.9997032e-01, 2.5324471e-05, 4.3797986e-06],\n",
       "       [9.9629515e-01, 5.2174804e-04, 3.1830813e-03],\n",
       "       [9.8398143e-01, 8.7412177e-03, 7.2774217e-03],\n",
       "       [9.9987805e-01, 8.9346417e-05, 3.2543485e-05],\n",
       "       [7.7851780e-02, 2.6578270e-03, 9.1949034e-01],\n",
       "       [9.9970394e-01, 2.4162755e-04, 5.4394237e-05],\n",
       "       [2.2369416e-02, 1.4142349e-03, 9.7621638e-01],\n",
       "       [9.9993122e-01, 5.1252351e-05, 1.7485212e-05],\n",
       "       [9.9404705e-01, 5.7402863e-03, 2.1269159e-04],\n",
       "       [8.0551201e-01, 1.8887764e-01, 5.6103738e-03],\n",
       "       [9.9510056e-01, 4.2973971e-03, 6.0201343e-04],\n",
       "       [9.0653306e-01, 5.2911550e-02, 4.0555406e-02],\n",
       "       [1.1087500e-02, 8.0032349e-01, 1.8858901e-01],\n",
       "       [1.2240897e-01, 4.4544559e-02, 8.3304650e-01],\n",
       "       [9.7423434e-01, 2.5514346e-02, 2.5128937e-04],\n",
       "       [9.9996650e-01, 2.5185787e-05, 8.2967144e-06],\n",
       "       [9.9346316e-01, 2.9786257e-04, 6.2390394e-03],\n",
       "       [6.5693301e-03, 1.1569052e-03, 9.9227375e-01],\n",
       "       [1.8169075e-01, 8.7570734e-03, 8.0955219e-01],\n",
       "       [9.9982762e-01, 1.4269679e-04, 2.9691408e-05],\n",
       "       [9.8976529e-01, 4.2277067e-03, 6.0070893e-03],\n",
       "       [3.8865298e-01, 6.0660899e-01, 4.7380663e-03],\n",
       "       [3.7447470e-01, 5.7074078e-04, 6.2495452e-01],\n",
       "       [9.7497016e-01, 2.9128164e-04, 2.4738643e-02],\n",
       "       [9.9357742e-01, 5.4705176e-03, 9.5201150e-04],\n",
       "       [3.9266083e-02, 9.5777893e-01, 2.9549534e-03],\n",
       "       [2.7540594e-03, 3.0111449e-03, 9.9423486e-01],\n",
       "       [1.4636001e-04, 9.4060873e-05, 9.9975961e-01],\n",
       "       [3.1207598e-04, 8.3799918e-05, 9.9960417e-01],\n",
       "       [9.9994946e-01, 4.6066081e-05, 4.4848780e-06],\n",
       "       [9.9962306e-01, 1.6797482e-04, 2.0889338e-04],\n",
       "       [9.9989271e-01, 9.3437673e-05, 1.3840196e-05],\n",
       "       [1.4638344e-02, 1.4626001e-01, 8.3910161e-01],\n",
       "       [9.9996126e-01, 3.6183745e-05, 2.4456619e-06],\n",
       "       [8.7554204e-01, 1.4582544e-03, 1.2299961e-01],\n",
       "       [2.8848773e-04, 4.4563782e-04, 9.9926585e-01],\n",
       "       [7.8071451e-01, 1.1051459e-03, 2.1818033e-01],\n",
       "       [9.9970633e-01, 2.7884953e-04, 1.4821546e-05],\n",
       "       [9.5929921e-05, 1.6955106e-04, 9.9973446e-01],\n",
       "       [9.9947447e-01, 5.0142664e-04, 2.4176648e-05],\n",
       "       [9.9995041e-01, 3.9291524e-05, 1.0215777e-05],\n",
       "       [2.2008299e-04, 1.8121480e-04, 9.9959868e-01],\n",
       "       [9.9944144e-01, 4.9001130e-04, 6.8471301e-05],\n",
       "       [2.1126000e-03, 7.0169121e-01, 2.9619616e-01],\n",
       "       [9.9981886e-01, 1.3711998e-04, 4.4048043e-05],\n",
       "       [9.9995029e-01, 4.0853873e-05, 8.8156085e-06],\n",
       "       [9.9890459e-01, 1.0387801e-03, 5.6677101e-05],\n",
       "       [9.9979693e-01, 1.7876826e-04, 2.4296636e-05],\n",
       "       [2.0833466e-02, 1.7642064e-03, 9.7740227e-01]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
